model_cfg: configs/models/fm-b-220m.json
data_catalog: data/catalog.yaml
mixture: pretrain_v0
precision: bf16
optimizer:
  name: adamw
  betas: [0.9, 0.95]
  weight_decay: 0.1
  lr: 2.0e-4
  warmup_steps: 4000
  schedule: cosine
distributed:
  backend: nccl
  fsdp: true
  fsdp_policy: full_shard
  grad_accum_steps: 16
logging:
  wandb: false
  tensorboard: true
  modal_ledger_interval: 10
losses:
  lambda_geo: 0.0
  modal:
    apply_on: ["planner"]
    lambda_mod: 0.25
    lambda_planner: 1.0
    lambda_token: 0.0
    tau_planner: 1.0
    tau_token: 1.0
    slot_len: 512
    view_window: 1
    slot_weights: [1.0, 0.5]
    stop_grad_projection: true
    eps: 1.0e-6
    clip_kl: 10.0
    token_topk: 256
ledger:
  lambda_mod: 0.25
  apply_on: ["planner", "token_spans"]
  span_tokens: ["<PLAN_START>", "<PLAN_END>"]
  view:
    slot_len: 512
    window: 1
gate:
  armijo_alpha: 1.0e-4
  trust_radius_init: 0.01
  kl_smooth_max: 1.0
